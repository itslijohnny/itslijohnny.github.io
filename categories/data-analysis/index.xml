<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data Analysis on Johnny's Blog</title><link>https://johnnyli.cc/categories/data-analysis/</link><description>Recent content in Data Analysis on Johnny's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Johnny Li</copyright><lastBuildDate>Sun, 14 Mar 2021 22:18:37 -0700</lastBuildDate><atom:link href="https://johnnyli.cc/categories/data-analysis/index.xml" rel="self" type="application/rss+xml"/><item><title>Price Strategy Based on Features Reputation</title><link>https://johnnyli.cc/p/price-strategy-based-on-features-reputation/</link><pubDate>Sun, 14 Mar 2021 22:18:37 -0700</pubDate><guid>https://johnnyli.cc/p/price-strategy-based-on-features-reputation/</guid><description>&lt;img src="https://johnnyli.cc/p/price-strategy-based-on-features-reputation/4BxDCOzgPulU89Y.jpg" alt="Featured image of post Price Strategy Based on Features Reputation" />&lt;p>&lt;a class="link" href="https://github.com/itslijohnny/ama" target="_blank" rel="noopener"
>&lt;img src="https://img.shields.io/badge/Ask%20me-anything-1abc9c.svg"
loading="lazy"
alt="Ask Me Anything !"
>&lt;/a> &lt;a class="link" href="https://www.python.org/" target="_blank" rel="noopener"
>&lt;img src="https://img.shields.io/badge/Made%20with-Python-1f425f.svg"
loading="lazy"
alt="made-with-python"
>&lt;/a> &lt;a class="link" href="https://www.mathjax.org/" target="_blank" rel="noopener"
>&lt;img src="https://img.shields.io/badge/Made%20with-MathJax-1f425f.svg"
loading="lazy"
alt="made-with-mathjax"
>&lt;/a>&lt;/p>
&lt;p>Customer reviews contain a large amount of information. One of the recurring subjects of NLP is to understand customer opinion through statement analysis of customer reviews. However, Basic Sentimental Classification can only tell customers' overall impression about the product. It can&amp;rsquo;t tell customers' opinions of specific features of the product. But, if we dive deeper into the customer reviews, we can get more information.
My goal is to extract features from reviews, identify each feature&amp;rsquo;s opinion, quantify the sentiment using econometrics, and then generate a price strategy based on it.&lt;/p>
&lt;p>The main techniques I used are:&lt;/p>
&lt;ol>
&lt;li>Web Clawing: Get customer reviews from Amazon.&lt;/li>
&lt;li>Nature Language Processing: Identify product features.&lt;/li>
&lt;li>Sentiment Analysis: Identify polarity of opinions regarding product features.&lt;/li>
&lt;li>Linear Regression: Regression analysis for opinions of the features and the price.&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>The &lt;code>Jupyter Notebook&lt;/code> goes along with this post &lt;strong>will&lt;/strong> be available in my Repo on &lt;a class="link" href="" >my Github&lt;/a> soon.&lt;/p>
&lt;/blockquote>
&lt;h2 id="data-overview">Data Overview&lt;/h2>
&lt;p>The product category I was working on is the home security camera. I scraped reviews of targe product and its competitors from Amazon.com. The dataset contains 53,657 reviews of 15 different home security cameras from Amazon.com with the following information for each one:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Name&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Description&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Product&lt;/strong>&lt;/td>
&lt;td>Name of the Product&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Username&lt;/strong>&lt;/td>
&lt;td>User&amp;rsquo;s ID&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Stars&lt;/strong>&lt;/td>
&lt;td>1-5 rating for the product&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Title&lt;/strong>&lt;/td>
&lt;td>The subject of the review&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Date&lt;/strong>&lt;/td>
&lt;td>The review date&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Review&lt;/strong>&lt;/td>
&lt;td>Review text&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Helpfulcount&lt;/strong>&lt;/td>
&lt;td>How many people click &amp;ldquo;Helpful&amp;rdquo; button&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>ReviewTotal&lt;/strong>&lt;/td>
&lt;td>How many comments under this review&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>The average length of reviews of the product is around 200 words, and most of the product has 2000 reviews.
&lt;img src="https://johnnyli.cc/p/price-strategy-based-on-features-reputation/bptextlenall.png"
width="398"
height="378"
srcset="https://johnnyli.cc/p/price-strategy-based-on-features-reputation/bptextlenall_hu2229a34b09e72ff045b11d917ee12791_21161_480x0_resize_box_3.png 480w, https://johnnyli.cc/p/price-strategy-based-on-features-reputation/bptextlenall_hu2229a34b09e72ff045b11d917ee12791_21161_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="105"
data-flex-basis="252px"
>
&lt;img src="https://johnnyli.cc/p/price-strategy-based-on-features-reputation/reviewcount.png"
width="398"
height="378"
srcset="https://johnnyli.cc/p/price-strategy-based-on-features-reputation/reviewcount_hu42a7441e2aeb265b38b30e1c8e11cef4_16874_480x0_resize_box_3.png 480w, https://johnnyli.cc/p/price-strategy-based-on-features-reputation/reviewcount_hu42a7441e2aeb265b38b30e1c8e11cef4_16874_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="105"
data-flex-basis="252px"
>&lt;/p>
&lt;p>Most of reviews are in the range of 4 years.
&lt;img src="https://johnnyli.cc/p/price-strategy-based-on-features-reputation/reviewdate.png"
width="1173"
height="375"
srcset="https://johnnyli.cc/p/price-strategy-based-on-features-reputation/reviewdate_hu9a39bf0df7bdae27ff97468837a614af_55329_480x0_resize_box_3.png 480w, https://johnnyli.cc/p/price-strategy-based-on-features-reputation/reviewdate_hu9a39bf0df7bdae27ff97468837a614af_55329_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="312"
data-flex-basis="750px"
>&lt;/p>
&lt;h2 id="methodology">Methodology&lt;/h2>
&lt;p>My approach includes 9 steps.&lt;/p>
&lt;div class="mermaid" style="
margin: 1.5em 0;
padding: 0 var(--card-padding);
">
graph TD
A( Amazon Review Raw Data ) --> B( Data Cleaning )
B --> C( Sentences Separation )
C --> D( Subject/Object Separation )
D --> E( Sentiment Scoring )
D --> F( Feature Extraction )
E --> G( Feature Reputation )
F --> G( Feature Reputation )
G --> H( Sentiment Quantifying )
H --> I( Price Premiums Prediction )
&lt;/div>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>&lt;img src="https://johnnyli.cc/p/price-strategy-based-on-features-reputation/2021-03-15-09-44-30.png"
width="636"
height="487"
srcset="https://johnnyli.cc/p/price-strategy-based-on-features-reputation/2021-03-15-09-44-30_hu561893eae45e95a4eb608be77a543eb5_27147_480x0_resize_box_3.png 480w, https://johnnyli.cc/p/price-strategy-based-on-features-reputation/2021-03-15-09-44-30_hu561893eae45e95a4eb608be77a543eb5_27147_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="130"
data-flex-basis="313px"
>&lt;/p>
&lt;p>To Be Continued.&lt;/p></description></item><item><title>Identify Customer Segments</title><link>https://johnnyli.cc/p/identify-customer-segments/</link><pubDate>Fri, 12 Mar 2021 21:42:22 -0800</pubDate><guid>https://johnnyli.cc/p/identify-customer-segments/</guid><description>&lt;img src="https://johnnyli.cc/p/identify-customer-segments/7dfc3OoaYZAnejX.jpg" alt="Featured image of post Identify Customer Segments" />&lt;p>This is one of the Udacity Data Scientist Nanodegree Project. This project aims to use unsupervised learning techniques to identify segments of the population from the core customer base for a mail-order sales company in Germany. Therefore, these segments can then be used to direct marketing campaigns towards audiences with the highest expected rate of returns.&lt;/p>
&lt;p>The techniques I used in this project include:&lt;/p>
&lt;ol>
&lt;li>Data cleaning&lt;/li>
&lt;li>Encoding and processing mixed-type feature&lt;/li>
&lt;li>Feature Scaling and Dimensionality Reduction&lt;/li>
&lt;li>Clustering&lt;/li>
&lt;li>Performance improvement with OpenBLAS&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>You can find the full analysis in &lt;a class="link" href="https://github.com/itslijohnny/identify-customer-segments/blob/main/Identify_Customer_Segments.ipynb" target="_blank" rel="noopener"
>my GitHub repo&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;h2 id="data">Data&lt;/h2>
&lt;p>The data files associated with this project (not included in this repository):&lt;/p>
&lt;ul>
&lt;li>&lt;code>Udacity_AZDIAS_Subset.csv&lt;/code>: Demographics data for the general population of Germany; 891,211 persons (rows) x 85 features (columns).&lt;/li>
&lt;li>&lt;code>Udacity_CUSTOMERS_Subset.csv&lt;/code>: Demographics data for customers of a mail-order company; 191,652 persons (rows) x 85 features (columns).&lt;/li>
&lt;li>&lt;code>Data_Dictionary.md&lt;/code>: Detailed information file about the features in the provided datasets.&lt;/li>
&lt;li>&lt;code>AZDIAS_Feature_Summary.csv&lt;/code>: Summary of feature attributes for demographics data; 85 features (rows) x 4 columns&lt;/li>
&lt;/ul>
&lt;h2 id="analysis-structure">Analysis Structure&lt;/h2>
&lt;ol>
&lt;li>Data exploration and data cleaning (85% of the analysis)&lt;/li>
&lt;li>Feature Engineering (One Hot, Scaling, and PCA)&lt;/li>
&lt;li>Clustering with k-means&lt;/li>
&lt;/ol>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>&lt;img src="https://johnnyli.cc/p/identify-customer-segments/Figure1.png"
width="615"
height="278"
srcset="https://johnnyli.cc/p/identify-customer-segments/Figure1_hudb085fa3cbbe78a5c1f4dd5854a76d63_10999_480x0_resize_box_3.png 480w, https://johnnyli.cc/p/identify-customer-segments/Figure1_hudb085fa3cbbe78a5c1f4dd5854a76d63_10999_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Figure 1. Proportions per cluster for general vs customer."
class="gallery-image"
data-flex-grow="221"
data-flex-basis="530px"
>&lt;/p>
&lt;p>I use the elbow method to find that 6 is the optimal number for clustering, which means the model segments customers and the general population into 6&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> groups. We can find the proportion of customers in cluster 2 is higher than the general population, which suggests people in cluster 2 are the target audience. We also find that, in cluster 3, the customer is underrepresented, which means people in that group are outside of the target demographics.&lt;/p>
&lt;p>&lt;img src="https://johnnyli.cc/p/identify-customer-segments/Figure2.png"
width="2299"
height="589"
srcset="https://johnnyli.cc/p/identify-customer-segments/Figure2_hue29e5bf3277d24f23bccf99a1420d40f_76006_480x0_resize_box_3.png 480w, https://johnnyli.cc/p/identify-customer-segments/Figure2_hue29e5bf3277d24f23bccf99a1420d40f_76006_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Figure 2. Major differences between Cluster 2 and Cluster 3"
class="gallery-image"
data-flex-grow="390"
data-flex-basis="936px"
>&lt;/p>
&lt;p>Comparing 2 segments, we can find there are some key differences. For example:&lt;/p>
&lt;ul>
&lt;li>Distance from building to point of sale: People in cluster 3 are closer to Pos then people in cluster 2.&lt;/li>
&lt;li>Wealth / Life Stage Typology: More people in cluster 2 are upper class&lt;/li>
&lt;li>Type of Building: Most builds in cluster 2 are residential build.&lt;/li>
&lt;li>Social status: Most people in cluster 2 are top earners and most people in cluster 3 are house owners.&lt;/li>
&lt;/ul>
&lt;h2 id="heading">&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">conda create -y -n p38openblas -c conda-forge &amp;#34;python=3.8&amp;#34; scipy &amp;#34;blas=*=*openblas&amp;#34;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="licensing-and-acknowledgements">Licensing and Acknowledgements&lt;/h2>
&lt;p>Udacity Data Scientist provided the starting code for this project.
Udacity partners at Bertelsmann Arvato Analytics provided the data.&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Cluster -1 is the group I added for checking the proportion of data that miss more than 30% information.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Donors Identification for CharityML</title><link>https://johnnyli.cc/p/donors-identification-for-charityml/</link><pubDate>Thu, 30 May 2019 01:03:50 +0000</pubDate><guid>https://johnnyli.cc/p/donors-identification-for-charityml/</guid><description>&lt;img src="https://johnnyli.cc/p/donors-identification-for-charityml/5cef9192b167778174.jpg" alt="Featured image of post Donors Identification for CharityML" />&lt;p>&lt;a class="link" href="https://lijohnny.com" target="_blank" rel="noopener"
>&lt;img src="https://img.shields.io/badge/Ask%20me-anything-1abc9c.svg"
loading="lazy"
>&lt;/a> &lt;a class="link" href="https://www.python.org/" target="_blank" rel="noopener"
>&lt;img src="https://img.shields.io/badge/Made%20with-Python-1f425f.svg"
loading="lazy"
>&lt;/a> &lt;a class="link" href="" >&lt;img src="https://img.shields.io/badge/Kaggle-Project-blue.svg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>In this project, I built machine learning models that best identifies potential donors for CharityML(a fictitious charity organization) with data collected for the U.S. census. To find the best approach, I performed EDA, feature engineering, and building training and predicting pipeline to evaluate and optimize the performance between different machine learning models.&lt;/p>
&lt;p>The modified census dataset consists of approximately 32,000 data points, with each datapoint having 13 features. This dataset is a modified version of the dataset published in the paper &lt;em>&amp;ldquo;Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid&amp;rdquo;,&lt;/em> by Ron Kohavi. You may find this paper &lt;a class="link" href="https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf" target="_blank" rel="noopener"
>online&lt;/a>, with the original dataset hosted on &lt;a class="link" href="https://archive.ics.uci.edu/ml/datasets/Census&amp;#43;Income" target="_blank" rel="noopener"
>UCI&lt;/a>.&lt;/p>
&lt;p>The model I have used:&lt;/p>
&lt;ul>
&lt;li>SGD Classifier&lt;/li>
&lt;li>AdaBoost&lt;/li>
&lt;li>Logistic Regression&lt;/li>
&lt;/ul>
&lt;p>You can see the code(iPython notebook) &lt;a class="link" href="https://github.com/itslijohnny/udacity-data-scientist-nanodegree/blob/master/Supervised/Project-CharityML/finding_donors_done.ipynb" target="_blank" rel="noopener"
>here&lt;/a>.&lt;/p></description></item></channel></rss>